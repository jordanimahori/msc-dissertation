
# This file loads predictions generated by our ridge regression model and calculates summary
# statistics for the performance of the model. Only the resnet-18-ms model from Yeh et al. (2020)
# is used due to unresolvable memory issues on Google Earth Engine. See note in README.


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import pickle
import statistics
from collections import defaultdict


# =================== LOAD DATA & DEFINE CONSTANTS =====================

# List of countries which appear in DHS surveys
DHS_COUNTRIES = [
    'angola', 'benin', 'burkina_faso', 'cameroon', 'cote_d_ivoire',
    'democratic_republic_of_congo', 'ethiopia', 'ghana', 'guinea', 'kenya',
    'lesotho', 'malawi', 'mali', 'mozambique', 'nigeria', 'rwanda', 'senegal',
    'sierra_leone', 'tanzania', 'togo', 'uganda', 'zambia', 'zimbabwe']

# Load resnet-18-ms model predictions
predictions = np.load('./data/resnet_ms/test_preds.npz')
labels = predictions.f.labels
predictions = predictions.f.test_preds

# TODO: Refactor this out to a separate file and generate the index there.
# For consistency with Yeh et al. (2020), I am loading their files and processing it as
# they suggest in africa_poverty repo. This snippet of code generates an index showing
# which prediction belongs to which feature.
npz = np.load('./data/yeh_et_al/dhs_image_hists.npz')
locs = npz['locs']
years = npz['years']

loc_dict_path = './data/yeh_et_al/dhs_loc_dict.pkl'
with open(loc_dict_path, 'rb') as f:
    loc_dict = pickle.load(f)

country_indices = defaultdict(list)  # country => np.array of indices
country_labels = np.zeros(19669, dtype=np.int32)  # np.array of country labels

for i, loc in enumerate(locs):
    country = loc_dict[tuple(loc)]['country']
    country_indices[country].append(i)

for i, country in enumerate(DHS_COUNTRIES):
    country_indices[country] = np.asarray(country_indices[country])
    indices = country_indices[country]
    country_labels[indices] = i


# ================== CALCULATE PREDICTION ERRORS ====================

# Calculate prediction errors
errors = labels - predictions
squared_errors = errors**2

# Create DataFrame for observations, predictions and errors
model_df = pd.DataFrame(
    columns=['lat', 'lon', 'country', 'year', 'label', 'resnet-18-ms', 'error', 'sq_error'])
model_df['lat'] = locs[:, 0]
model_df['lon'] = locs[:, 1]
model_df['country'] = np.asarray(DHS_COUNTRIES)[country_labels]
model_df['year'] = years
model_df['label'] = labels
model_df['resnet-18-ms'] = predictions
model_df['error'] = errors
model_df['sq_error'] = squared_errors


# Calculate overall model performance
mse = statistics.mean(squared_errors)
r_sq = 1 - (sum((labels - predictions)**2))/(sum(labels**2))   # R^2 = 1 - RSS/TSS

# Plot predictions against labels
plt.scatter(labels, predictions, alpha=0.01)
plt.show()


# Calculate model performance by country
mse_country = defaultdict(list)
for country in DHS_COUNTRIES:
    index = country_indices[country]
    mse_country[country] = statistics.mean(model_df['sq_error'][index])

r_sq_country = defaultdict(list)
for country in DHS_COUNTRIES:
    index = country_indices[country]
    rss = sum((model_df['label'][index] - model_df['resnet-18-ms'][index])**2)
    tss = sum((model_df['label'][index])**2)
    r_sq_country[country] = 1 - (rss/tss)






